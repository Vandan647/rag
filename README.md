# rag
Built a robust data pipeline using LangChain to orchestrate document loading (PyPDFLoader), text chunking (RecursiveCharacterTextSplitter), and embedding generation (Hugging Face).
Developed a full-stack application that enables users to have natural language conversations with their PDF documents. The system leverages a Retrieval-Augmented Generation (RAG) pipeline to provide accurate, context-aware answers sourced directly from the provided texts.

Backend: Built a robust data pipeline using LangChain to orchestrate document loading (PyPDFLoader), text chunking (RecursiveCharacterTextSplitter), and embedding generation (Hugging Face).

Core Logic: Utilized ChromaDB for efficient vector storage and similarity search, coupled with the Groq API for high-speed LLM (Llama 3) inference.

Frontend: Created a clean, interactive user interface with Streamlit, allowing for real-time querying and response visualization.
